---
title: "Surge Forecasting Evaluation"
author: "Jack Rossi"
date: "June 27, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Summary

The objective of this code is to specify a comprehensive set of forecasting techniques. Each forecast will be a unique combination of four dimensions: 

1. Objective - what are we trying to predict? For all forecasts discussed, we want to identify whether the maximum Occupancy Rate in a day meets or exceeds a 1.50 threshold. 

2. Timeframe - At what time in the day do we desire to make a forecast? E.G. a single known decision time, or some amount of time before the true objective. 

3. Predictor Metric - What output metric are we forecasting in order to guess at the Objective? E.G., NIS, Occupancy, or Forecasted Occupancy.

4. Seed - Over what period of time do we average the output metric to determine our initial "state of the ED" from which a forecast is made? E.G. Several hours, minutes or instantaneous.

For each forecasting technique, I will present its rationale, specifics, and then estimate its performance using an ROC curve and the AUC metric. I hope that other ideas for forecasting techniques will emerge as we begin to return results. When we feel confident in a short list of forecasting techniques, we can further compare their performance using the regression-type metrics and visualizations I proposed in a previous update.

```{r dpreload}
library("plyr")
library("ROCR")
library("ggplot2")

get_rooms <- function(hour){
  
  if(hour%%24 >= 0){
    hour = hour%%24
    }
  
  if(hour %in% c(11,12,13,14,15,16,17,18,19,20,21,22,23,24,0)){
    Rooms = 42}
  else if (hour == 1){
    Rooms = 32}
  else if (hour %in% c(2, 3)){
    Rooms = 25}
  else if (hour %in% c(4, 5, 6, 7, 8)){
    Rooms = 22} 
  else if (hour == 9){
    Rooms = 26}
  else if (hour == 10){
    Rooms = 36}
  else {
    Rooms = NA}
  
  return(Rooms)
}

get_FC_rooms <- function(hrBlock, minBlock, FCHours = 2){
  #Sum up the number available rooms in the next FChours, weighted by the time spent with those rooms
  if (FCHours == 1){return(get_rooms(hrBlock))
  }
  FCRooms = 0
  
  for (g in 1:FCHours){
    FCRooms = FCRooms + get_rooms(hrBlock + g - 1)*(60-minBlock) + get_rooms(hrBlock + g)*minBlock  
  }
  FCRooms = FCRooms/(60*FCHours)
}
 

```

```{r data}
#loading data; formatting date objects
#datadirectory <- "C:/Users/jack1/Documents/Documents/Research CHP/"
datadirectory <- "C:\\Users\\louis\\Desktop\\Box Sync\\CHP ED Project\\Surge Items\\"
datafile <- paste(datadirectory, "ALL_DATA.csv", sep = "")
ED <- read.csv("ALL_DATA.csv", header = TRUE)

colnames(ED)[1] = "Encounter.ID"
ED$Arrival <- as.POSIXct(ED$Arrival, format = "%m/%d/%Y %I:%M %p")
ED$Time.Left.ED <- as.POSIXct(ED$Time.Left.ED, format = "%m/%d/%Y %I:%M %p") 
ED$ED.Room.Time <- as.POSIXct(ED$ED.Room.Time, format = "%m/%d/%Y %I:%M %p")
ED$Seen.By.Resident <- as.POSIXct(ED$Seen.By.Resident, format = "%m/%d/%Y %I:%M %p")
ED$Seen.By.Fellow <- as.POSIXct(ED$Seen.By.Fellow, format = "%m/%d/%Y %I:%M %p")
ED$Seen.By.Attending <- as.POSIXct(ED$Seen.By.Attending, format = "%m/%d/%Y %I:%M %p")

#often there are multiple rows for a single patient
ED <- ED[!duplicated(ED$Encounter.ID),]

tst <- as.POSIXct("2017-1-29 07:00")
tet <- as.POSIXct("2017-3-26 06:50")
tev <- seq(from = 0, to = as.integer(difftime(tet, tst, units = "secs")), by = 60*10)
testdata <- data.frame(tst + tev)


##remove ed entries whose LOS is over 24 hours. These are likely errors
ED <- ED[ED$LOS <= 24*60,] #== 1440 minutes

colnames(testdata)[1] <- "Time"

testdata$ptime <- strftime(testdata$Time, format = "%A %R")
testdata$dday <- as.POSIXlt(testdata$Time)$yday
testdata$wkday <- weekdays(testdata$Time)
testdata$hr <- as.POSIXlt(testdata$Time)$hour
testdata$min <- as.POSIXlt(testdata$Time)$min

#adopt delayed day convention
testdata$dday[testdata$hr >= 7] <- testdata$dday[testdata$hr >= 7] + 1


for (m in 1:length(testdata$Time)){
  WholeED <- ED[!is.na(ED$Arrival) & !is.na(ED$Time.Left.ED)  & 
      ED$Arrival <= testdata$Time[m] & ED$Time.Left.ED > testdata$Time[m],]
  testdata$NIS[m] <- length(WholeED$Encounter.ID)
  testdata$Rooms[m] <- get_rooms(testdata$hr[m])
  testdata$FCRooms[m] <- get_FC_rooms(testdata$hr[m], testdata$min[m])
  testdata$FCRooms1[m] <- get_FC_rooms(testdata$hr[m], testdata$min[m], 1)
}


testdata$OccRate <- testdata$NIS/testdata$Rooms
testdata$FCOccRate <- testdata$NIS/testdata$FCRooms
testdata$FCOccRate1 <- testdata$NIS/testdata$FCRooms1
```


```{r make_ptyp}
#create schedule to contain training data for creating ptyp week
st <- as.POSIXct("2016-12-4")
et <- as.POSIXct("2017-1-29")
ev <- seq(from = 0, to = as.integer(difftime(et, st, units = "secs")), by = 60*10)
sched <- data.frame(st + ev)
colnames(sched)[1] <- "Time"

sched$wkday <- weekdays(sched$Time)
sched$hour <- as.POSIXlt(sched$Time)$hour
sched$min <- as.POSIXlt(sched$Time)$min

#calculate metrics for training data
for (m in 1:length(sched$Time)){
  WholeED <- ED[!is.na(ED$Arrival) & !is.na(ED$Time.Left.ED) & 
      ED$Arrival <= sched$Time[m] & ED$Time.Left.ED > sched$Time[m],]
  sched$NIS[m] <- length(WholeED$Encounter.ID)
  sched$Rooms[m] <- get_rooms(as.POSIXlt(sched$Time[m])$hour)
  sched$FCRooms[m] <- get_FC_rooms(as.POSIXlt(sched$Time[m])$hour, as.POSIXlt(sched$Time[m])$min)
  sched$FCRooms1[m] <- get_FC_rooms(as.POSIXlt(sched$Time[m])$hour, as.POSIXlt(sched$Time[m])$min, 1)
}

sched$OccRate <- sched$NIS/sched$Rooms
sched$FCOccRate <- sched$NIS/sched$FCRooms
sched$FCOccRate1 <- sched$NIS/sched$FCRooms1

##create a prototypical week
pst <- as.POSIXct("2017-1-1 07:00")
pev <- seq(from = 0, to = 7*24*60*60-1, by = 60*10)
prt <- pst + pev

ptyp <- data.frame(prt)
colnames(ptyp)[1] <- "Time"
ptyp$wkday <- weekdays(ptyp$Time)

#calculate ptyp week by averaging all metrics for each unique combo of wkday, hour, minute
for (i in 1:length(ptyp$Time)){
  day <- ptyp$wkday[i]
  hour <- as.POSIXlt(ptyp$Time[i])$hour
  min <- as.POSIXlt(ptyp$Time[i])$min
  
  ext <- sched[sched$wkday == day & sched$hour == hour & sched$min ==   min,]

  ptyp$AvgOcc[i] <- mean(ext$OccRate)
  ptyp$AvgNIS[i] <- mean(ext$NIS)
  ptyp$AvgFCOcc[i] <- mean(ext$FCOccRate)
  ptyp$AvgFCOcc1[i] <- mean(ext$FCOccRate1)
  ptyp$N[i] <- length(ext$Time)
}

ptyp$hr <- as.POSIXlt(ptyp$Time)$hour
ptyp$dday <- as.POSIXlt(ptyp$Time)$yday
#apply delayed day convention
ptyp$dday[ptyp$hr >= 7] <- ptyp$dday[ptyp$hr >= 7] + 1
ptyp$ptime <- strftime(ptyp$Time, format = "%A %R")

#change prototypical week into a series of changes in OccRate
delta <- data.frame(ptyp$Time)
delta$ptime <- strftime(ptyp$Time, format = "%A %R")
colnames(delta)[1] <- "Time"
delta$wkday <- weekdays(delta$Time)
delta$dOcc[1] = 0
delta$dFCOcc[1] = 0
delta$dFCOcc1[1] = 0 
for (g in 1:length(ptyp$Time)){
  delta$dOcc[g] = ptyp$AvgOcc[g+1] - ptyp$AvgOcc[g]
  delta$dNIS[g] = ptyp$AvgNIS[g+1] - ptyp$AvgNIS[g]
  delta$dFCOcc[g] = ptyp$AvgFCOcc[g+1] - ptyp$AvgFCOcc[g]
  delta$dFCOcc1[g] = ptyp$AvgFCOcc1[g+1] - ptyp$AvgFCOcc1[g]
}

delta$dOcc[length(delta$dOcc)] <- 0
delta$dNIS[length(delta$dNIS)] <- 0 
delta$dFCOcc[length(delta$dFCOcc)] <- 0

#create list object to hold AUC results
aucs <- list()
```

The first four techniques are simple Occupancy Rate forecasts conducted at static decision points. They use either 1 or 2 hour seeds.

##Forecast 1

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 4pm Daily

Seed: 2 hours

```{r forecast_1}
##Forecast 1
testdata$PredOcc_4p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 16 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredOcc_4p[y] = mean(testdata$OccRate[(y-11):y])   
  }
  else if (!is.na(testdata$PredOcc_4p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15))) {
    testdata$PredOcc_4p[y] = testdata$PredOcc_4p[y-1] +
      delta$dOcc[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_4p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize = TRUE)

aucs[[1]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```


##Forecast 2

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: *8pm* Daily

Seed: 2 hours

```{r forecast_2}
##Forecast 2
testdata$PredOcc_8p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 20 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredOcc_8p[y] = mean(testdata$OccRate[(y-11):y])   
  }
  else if (!is.na(testdata$PredOcc_8p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15,16,17,18,19))) {
    testdata$PredOcc_8p[y] = testdata$PredOcc_8p[y-1] +
      delta$dOcc[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_8p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[2]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

##Forecast 3

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 4pm Daily

Seed: *1* hour


```{r forecast_3}
##Forecast 3
testdata$PredOcc_4p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 16 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredOcc_4p[y] = mean(testdata$OccRate[(y-5):y])   
  }
  else if (!is.na(testdata$PredOcc_4p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15))) {
    testdata$PredOcc_4p[y] = testdata$PredOcc_4p[y-1] +
      delta$dOcc[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_4p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize = TRUE)

aucs[[3]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```

##Forecast 4

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 8pm Daily

Seed: 1 hour


```{r forecast_4}
##Forecast 4
testdata$PredOcc_8p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 20 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredOcc_8p[y] = mean(testdata$OccRate[(y-5):y])   
  }
  else if (!is.na(testdata$PredOcc_8p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15,16,17,18,19))) {
    testdata$PredOcc_8p[y] = testdata$PredOcc_8p[y-1] +
      delta$dOcc[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_8p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[4]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```

The next four techniques again vary 1 or 2 hour seeds at 4 and 8 PM. This time, we use NIS to guess at the maximum Occupancy Level.

##Forecast 5

Objective: Daily Maximum Occupancy >= 1.50

Predictor: *NIS*

Timeframe: 4pm Daily

Seed: 2 hours


```{r forecast_5}
##Forecast 5
testdata$PredNIS_4p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 16 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredNIS_4p[y] = mean(testdata$NIS[(y-11):y])   
  }
  else if (!is.na(testdata$PredNIS_4p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15))) {
    testdata$PredNIS_4p[y] = testdata$PredNIS_4p[y-1] +
      delta$dNIS[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_NIS = max(x$PredNIS_4p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_NIS"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize = TRUE)

aucs[[5]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

##Forecast 6

Objective: Daily Maximum Occupancy >= 1.50

Predictor: NIS

Timeframe: 8pm Daily

Seed: 2 hours


```{r forecast_6}
##Forecast 6
testdata$PredNIS_8p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 20 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredNIS_8p[y] = mean(testdata$NIS[(y-11):y])   
  }
  else if (!is.na(testdata$PredNIS_8p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15,16,17,18,19))) {
    testdata$PredNIS_8p[y] = testdata$PredNIS_8p[y-1] +
      delta$dNIS[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_NIS = max(x$PredNIS_8p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_NIS"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[6]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

##Forecast 7

Objective: Daily Maximum Occupancy >= 1.50

Predictor: NIS

Timeframe: 4pm Daily

Seed: 1 hour


```{r forecast_7}
##Forecast 7
testdata$PredNIS_4p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 16 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredNIS_4p[y] = mean(testdata$NIS[(y-5):y])   
  }
  else if (!is.na(testdata$PredNIS_4p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15))) {
    testdata$PredNIS_4p[y] = testdata$PredNIS_4p[y-1] +
      delta$dNIS[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_NIS = max(x$PredNIS_4p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_NIS"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize = TRUE)

aucs[[7]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

##Forecast 8

Objective: Daily Maximum Occupancy >= 1.50

Predictor: NIS

Timeframe: 8pm Daily

Seed: 1 hour


```{r forecast_8}
##Forecast 8
testdata$PredNIS_8p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 20 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredNIS_8p[y] = mean(testdata$NIS[(y-5):y])   
  }
  else if (!is.na(testdata$PredNIS_8p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15,16,17,18,19))) {
    testdata$PredNIS_8p[y] = testdata$PredNIS_8p[y-1] +
      delta$dNIS[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_NIS = max(x$PredNIS_8p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_NIS"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[8]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

In general, it appears that Occupancy is a better predictor of itself than is NIS. Also, higher AUC values seem to result from smaller seeds.

When comparing ROC curves with similar AUC values, I think we should favor plots with high TPR as well as FPR not exceeding 0.1. Especially in the summer when Surges are more scarce, an FPR above 0.1 would translate to more than 2 unnecessary Surge calls per three weeks. The threshold that is chosen in operation should be varied season to season to compensate for the changing ratios of positive and negative conditions.  

The next forecast is one possible representation of forecasting at each team huddle. Huddles occur every two hours, and here we represent the earliest possible warning we could receive, such that the true Surge would begin just before the next team huddle. 

##Forecast 9

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 2 hours before true max

Seed: 2 hours


```{r forecast_9}
testdata$PredOcc_2hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #and through each data point contained in those days
  for (n in which(testdata$dday == m)){
    #do nothing to the first 22 data points in the data set: else the equation below would throw an error
    if (n < 23){
    
    }
    else if(testdata$OccRate[n] == max(testdata$OccRate[testdata$dday==m])){
      testdata$PredOcc_2hr[n-11] <- mean(testdata$OccRate[(n-22):(n-11)]) 
      break
    } 
  }                        
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredOcc_2hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredOcc_2hr[n] <- testdata$PredOcc_2hr[n-1] +
      delta$dOcc[delta$wkday == testdata$wkday[n-1] & 
                 as.POSIXlt(delta$Time)$hour == testdata$hr[n-1] &
                 as.POSIXlt(delta$Time)$min == testdata$min[n-1]]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_2hr, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[9]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```

Knowing that smaller seeds tend to produce better results, we can claim that Occupancy Rate (or NIS) does not fluctuate much, but instead follows a consistent upward or downward trend. Reducing the seed to 0 in the following forecasts produces the most responsive forecast.

##Forecast 10

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 4pm Daily

Seed: 0 


```{r forecast_10}
##Forecast 1
testdata$PredOcc_4p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 16 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredOcc_4p[y] = testdata$OccRate[y] 
  }
  else if (!is.na(testdata$PredOcc_4p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15))) {
    testdata$PredOcc_4p[y] = testdata$PredOcc_4p[y-1] +
      delta$dOcc[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_4p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize = TRUE)
aucs[[10]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

##Forecast 11

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 8pm Daily

Seed: 0 


```{r forecast_11}
##Forecast 2
testdata$PredOcc_8p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 20 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredOcc_8p[y] = testdata$OccRate[y]   
  }
  else if (!is.na(testdata$PredOcc_8p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15,16,17,18,19))) {
    testdata$PredOcc_8p[y] = testdata$PredOcc_8p[y-1] +
      delta$dOcc[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_8p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[11]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

##Forecast 12

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 2 hours before true max

Seed: 0 


```{r forecast_12}
testdata$PredOcc_2hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #and through each data point contained in those days
  for (n in which(testdata$dday == m)){
    #do nothing to the first 22 data points in the data set: else the equation below would throw an error
    if (n < 23){
    
    }
    else if(testdata$OccRate[n] == max(testdata$OccRate[testdata$dday==m])){
      testdata$PredOcc_2hr[n-11] <- testdata$OccRate[n-11]
      break
    } 
  }
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredOcc_2hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredOcc_2hr[n] <- testdata$PredOcc_2hr[n-1] +
      delta$dOcc[delta$wkday == testdata$wkday[n-1] & 
                 as.POSIXlt(delta$Time)$hour == testdata$hr[n-1] &
                 as.POSIXlt(delta$Time)$min == testdata$min[n-1]]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_2hr, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[12]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```
Using a zero seed produces nice results. Tracing the ROC curve above, it appears that we can predict 80% of Surges two hours in advance, with perhaps just a 5% false alarm rate. 

To be safe, I wanted to check that using the 0 seed with NIS did not cause its performance to increase greatly. 

##Forecast 13

Objective: Daily Maximum Occupancy >= 1.50

Predictor: NIS

Timeframe: 4pm Daily

Seed: 0


```{r forecast_13}
##Forecast 7
testdata$PredNIS_4p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 16 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredNIS_4p[y] = testdata$NIS[y] 
  }
  else if (!is.na(testdata$PredNIS_4p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15))) {
    testdata$PredNIS_4p[y] = testdata$PredNIS_4p[y-1] +
      delta$dNIS[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_NIS = max(x$PredNIS_4p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_NIS"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize = TRUE)

aucs[[13]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

##Forecast 14

Objective: Daily Maximum Occupancy >= 1.50

Predictor: NIS

Timeframe: 8pm Daily

Seed: 0


```{r forecast_14}
##Forecast 8
testdata$PredNIS_8p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 20 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredNIS_8p[y] = testdata$NIS[y]  
  }
  else if (!is.na(testdata$PredNIS_8p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15,16,17,18,19))) {
    testdata$PredNIS_8p[y] = testdata$PredNIS_8p[y-1] +
      delta$dNIS[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                                                             as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                 as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_NIS = max(x$PredNIS_8p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_NIS"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[14]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```
NIS still seems to lag behind Occupancy Rate in performance. 

The next forecast's decision point depends on the time at which the maximum is reached on each weekday on average. This is a more advanced version of the static decision point.

##Forecast 15

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 2 hours before prototypical max

Seed: 0


```{r forecast_15}

fctimes <- ddply(ptyp, ~dday, function(x){
  Time.max <- max(x$AvgOcc)
  data.frame(Time.time <- x$Time[x$AvgOcc == Time.max][1])
})

colnames(fctimes)[2] <- "Time"
fctimes$ptime <- strftime(fctimes$Time, format = "%A %R")


testdata$PredOcc_2hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #For each data point in a particular dday
  for (n in which(testdata$dday == m)){
    #do nothing to the first 11 data points in the data set: else the equation below would throw an error
    if (n < 12){
    
    }
    else if(testdata$ptime[n] %in% fctimes$ptime) {
      testdata$PredOcc_2hr[n-11] <- testdata$OccRate[n-11]
      break
    } 
    
  }
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredOcc_2hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredOcc_2hr[n] <- testdata$PredOcc_2hr[n-1] +
      delta$dOcc[testdata$ptime[n-1] == delta$ptime]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_2hr, na.rm = TRUE)))

#daylight savings produces an error on Mar 12. Remove this dday from consideration.
labs = labs[labs$dday != 70,]
preds = preds[preds$dday != 70,]
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[15]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]



```

The next method assumes a lack of knowledge about the distribution of surge incidence. I assume that the probability of a surge is uniformly distributed in the time between subsequent bi-hourly huddles. On average, then, a surge will occur an hour after a huddle. 

##Forecast 16

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Occupancy Rate

Timeframe: 1 hour before true max

Seed: 0


```{r forecast_16}
testdata$PredOcc_2hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #and through each data point contained in those days
  for (n in which(testdata$dday == m)){
    #do nothing to the first 22 data points in the data set: else the equation below would throw an error
    if (n < 6){
    
    }
    else if(testdata$OccRate[n] == max(testdata$OccRate[testdata$dday==m])){
      testdata$PredOcc_2hr[n-5] <- testdata$OccRate[n-5]
      break
    } 
  }
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredOcc_2hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredOcc_2hr[n] <- testdata$PredOcc_2hr[n-1] +
      delta$dOcc[delta$wkday == testdata$wkday[n-1] & 
                 as.POSIXlt(delta$Time)$hour == testdata$hr[n-1] &
                 as.POSIXlt(delta$Time)$min == testdata$min[n-1]]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredOcc_2hr, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[16]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```
At one hour out, it looks like we can do slightly better than 80% TPR at again 5% FPR. We would obviously expect TPR to increase and FPR to decrease as forecasts are made closer to the actual Surge. 

Next I decided to try the Forecasted (FC) Occupancy rate. This metric retains NIS in the numerator, but the denominator is a time-weighted average of the number of rooms to be open in the next two hours. This metric captures the fact that a full wait room is worse if units are supposed to close in the near future. 

##Forecast 17

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Forecasted Occupancy Rate

Timeframe: 8pm Daily

Seed: 0 


```{r forecast_17}
##Forecast 17
testdata$PredFCOcc_8p <- NA

for (y in 2:length(testdata$Time)){
  if (as.POSIXlt(testdata$Time[y])$hour== 20 & as.POSIXlt(testdata$Time[y])$min == 0){
    testdata$PredFCOcc_8p[y] = testdata$FCOccRate[y]   
  }
  else if (!is.na(testdata$PredFCOcc_8p[y-1]) & !(as.POSIXlt(testdata$Time[y])$hour %in% c(7,8,9,10,11,12,13,14,15,16,17,18,19))) {
    testdata$PredFCOcc_8p[y] = testdata$PredFCOcc_8p[y-1] +
      delta$dFCOcc[as.POSIXlt(testdata$Time[y-1])$wday == as.POSIXlt(delta$Time)$wday &                         as.POSIXlt(testdata$Time[y-1])$hour == as.POSIXlt(delta$Time)$hour &
                   as.POSIXlt(testdata$Time[y-1])$min == as.POSIXlt(delta$Time)$min]
  }

}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredFCOcc_8p, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[17]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
```

##Forecast 18

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Forecasted Occupancy Rate

Timeframe: 2 hours before true max

Seed: 0 


```{r forecast_18}
testdata$PredFCOcc_2hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #and through each data point contained in those days
  for (n in which(testdata$dday == m)){
    #do nothing to the first 22 data points in the data set: else the equation below would throw an error
    if (n < 12){
    
    }
    else if(testdata$OccRate[n] == max(testdata$OccRate[testdata$dday==m])){
      testdata$PredFCOcc_2hr[n-11] <- testdata$FCOccRate[n-11]
      break
    } 
  }
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredFCOcc_2hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredFCOcc_2hr[n] <- testdata$PredFCOcc_2hr[n-1] +
      delta$dFCOcc[delta$wkday == testdata$wkday[n-1] & 
                 as.POSIXlt(delta$Time)$hour == testdata$hr[n-1] &
                 as.POSIXlt(delta$Time)$min == testdata$min[n-1]]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredFCOcc_2hr, na.rm = TRUE)))
#no predictions are made on days 69 and 84. One these days, since the FCOcc max is from a surge the previous night. 
#labs = labs[preds$dday != 69 & preds$dday != 84,]
#preds = preds[preds$dday != 69 & preds$dday != 84,]
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[18]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```
Two errors were produced when in this last forecast. This was because two day's maximum FC Occupancy occurred at the beginning of the day, (7am) a remnant of the previous night's surge. This led me to believe the to 7a-7a convention may not be appropriate for the FC Occupancy metric.

In an appendix I plotted the prototypical week in Forecasted Occupancy, and determined that 8a-8a was a more natural cut off. We can change this convention for future work, but for now I do not expect it to change the results much. 

Next I thought that the number of rooms open in the very near term future may be most important. In the following, the predictor metric is the forecasted occupancy rate with average room availability calculated over 1 hour instead of 2. 

##Forecast 19

Objective: Daily Maximum Occupancy >= 1.50

Predictor: *(1 Hour)*-Forecasted Occupancy Rate 

Timeframe: 2 hours before true max

Seed: 0 

```{r forecast_19}
testdata$PredFCOcc1_2hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #and through each data point contained in those days
  for (n in which(testdata$dday == m)){
    #do nothing to the first 22 data points in the data set: else the equation below would throw an error
    if (n < 12){
    
    }
    else if(testdata$OccRate[n] == max(testdata$OccRate[testdata$dday==m])){
      testdata$PredFCOcc1_2hr[n-11] <- testdata$FCOccRate1[n-11]
      break
    } 
  }
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredFCOcc1_2hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredFCOcc1_2hr[n] <- testdata$PredFCOcc1_2hr[n-1] +
      delta$dFCOcc1[delta$wkday == testdata$wkday[n-1] & 
                 as.POSIXlt(delta$Time)$hour == testdata$hr[n-1] &
                 as.POSIXlt(delta$Time)$min == testdata$min[n-1]]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredFCOcc1_2hr, na.rm = TRUE)))
#no predictions are made on days 69 and 84. One these days, since the FCOcc max is from a surge the previous night. 
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[19]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```
The AUC in this case is quite similar, however the 2-hour time average gives a better TPR for FPR fixed at 5%. The next forecast settles on this longer time average. 

Returning to the trade off between timeliness and predictive power, I wanted to see how well we could predict a surge at an hour out. 

##Forecast 20

Objective: Daily Maximum Occupancy >= 1.50

Predictor: Forecasted Occupancy Rate

Timeframe: 1 hours before true max

Seed: 0 

```{r forecast_20}
testdata$PredFCOcc_1hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #and through each data point contained in those days
  for (n in which(testdata$dday == m)){
    #do nothing to the first 11 data points in the data set: else the equation below would throw an error
    if (n < 6){
    
    }
    else if(testdata$OccRate[n] == max(testdata$OccRate[testdata$dday==m])){
      testdata$PredFCOcc_1hr[n-5] <- testdata$FCOccRate[n-5]
      break
    } 
  }
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredFCOcc_1hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredFCOcc_1hr[n] <- testdata$PredFCOcc_1hr[n-1] +
      delta$dFCOcc[delta$wkday == testdata$wkday[n-1] & 
                 as.POSIXlt(delta$Time)$hour == testdata$hr[n-1] &
                 as.POSIXlt(delta$Time)$min == testdata$min[n-1]]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredFCOcc_1hr, na.rm = TRUE)))
#no predictions are made on days 69 and 84. One these days, since the FCOcc max is from a surge the previous night. 
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[20]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```

I believe the results above to be conclusive in selecting this forecasting method as our best. However, the jaggedness of our ROC curves suggest that these results may be biased by a lack of data. So, after fixing the 8a-to-8a day convention, I sought to reevaluate this forecasting method using data from the same time period in 2016.

Because of lack of 2015 data, I am not able to retrain the model for the previous year. Instead, I will use the current trained model, and adjust the older test data by a factor that equals the ratio of 2017 volume through the testing timeframe to the 2016 volume through the same. 

```{r newdata}
#calculating 2017 volume for adjustment
volume17 = length(ED$Encounter.ID[ED$Arrival >= tst & ED$Arrival <= tet])

#calculating 2016 volume for adjustment
tst <- as.POSIXct("2016-1-31 08:00")
tet <- as.POSIXct("2016-3-28 07:50")

volume16 = length(ED$Encounter.ID[ED$Arrival >= tst & ED$Arrival <= tet])

growth  = volume17/volume16

tev <- seq(from = 0, to = as.integer(difftime(tet, tst, units = "secs")), by = 60*10)
testdata <- data.frame(tst + tev)


##remove ed entries whose LOS is over 24 hours. These are likely errors
ED <- ED[ED$LOS <= 24*60,] #== 1440 minutes

colnames(testdata)[1] <- "Time"

testdata$ptime <- strftime(testdata$Time, format = "%A %R")
testdata$dday <- as.POSIXlt(testdata$Time)$yday
testdata$wkday <- weekdays(testdata$Time)
testdata$hr <- as.POSIXlt(testdata$Time)$hour
testdata$min <- as.POSIXlt(testdata$Time)$min

#adopt delayed day convention
testdata$dday[testdata$hr >= 8] <- testdata$dday[testdata$hr >= 8] + 1


for (m in 1:length(testdata$Time)){
  WholeED <- ED[!is.na(ED$Arrival) & !is.na(ED$Time.Left.ED)  & 
      ED$Arrival <= testdata$Time[m] & ED$Time.Left.ED > testdata$Time[m],]
  testdata$NIS[m] <- length(WholeED$Encounter.ID)
  testdata$Rooms[m] <- get_rooms(testdata$hr[m])
  testdata$FCRooms[m] <- get_FC_rooms(testdata$hr[m], testdata$min[m])
  testdata$FCRooms1[m] <- get_FC_rooms(testdata$hr[m], testdata$min[m], 1)

}

#account for growth 
testdata$NIS <- growth*testdata$NIS

testdata$OccRate <- testdata$NIS/testdata$Rooms
testdata$FCOccRate <- testdata$NIS/testdata$FCRooms
testdata$FCOccRate1 <- testdata$NIS/testdata$FCRooms1
```

##Forecast 20.1

```{r forecast_20.1}
testdata$PredFCOcc_1hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #and through each data point contained in those days
  for (n in which(testdata$dday == m)){
    #do nothing to the first 11 data points in the data set: else the equation below would throw an error
    if (n < 6){
    
    }
    else if(testdata$OccRate[n] == max(testdata$OccRate[testdata$dday==m])){
      testdata$PredFCOcc_1hr[n-5] <- testdata$FCOccRate[n-5]
      break
    } 
  }
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredFCOcc_1hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredFCOcc_1hr[n] <- testdata$PredFCOcc_1hr[n-1] +
      delta$dFCOcc[delta$wkday == testdata$wkday[n-1] & 
                 as.POSIXlt(delta$Time)$hour == testdata$hr[n-1] &
                 as.POSIXlt(delta$Time)$min == testdata$min[n-1]]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredFCOcc_1hr, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[20]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```

##Forecast 18.1

```{r forecast_18.1}
testdata$PredFCOcc_2hr <- NA

#loop through the unique days in the data - two inner loops will first find max OccRate in a day, and then #fill in the OccRate predictions based on the location and value of that maximum
for (m in min(testdata$dday):max(testdata$dday)){
  #and through each data point contained in those days
  for (n in which(testdata$dday == m)){
    #do nothing to the first 22 data points in the data set: else the equation below would throw an error
    if (n < 12){
    
    }
    else if(testdata$OccRate[n] == max(testdata$OccRate[testdata$dday==m])){
      testdata$PredFCOcc_2hr[n-11] <- testdata$FCOccRate[n-11]
      break
    } 
  }
  for (n in which(testdata$dday == m)){
    if (n == 1){
    ##do nothing  
    }
    else if((!is.na(testdata$PredFCOcc_2hr[n-1])) & testdata$dday[n-1] == testdata$dday[n]){
    testdata$PredFCOcc_2hr[n] <- testdata$PredFCOcc_2hr[n-1] +
      delta$dFCOcc[delta$wkday == testdata$wkday[n-1] & 
                 as.POSIXlt(delta$Time)$hour == testdata$hr[n-1] &
                 as.POSIXlt(delta$Time)$min == testdata$min[n-1]]
    }
  }
  
}

labs = ddply(testdata, ~dday, function(x) c(Surge = length(unique(x$dday[x$OccRate >= 1.50]))))
preds =  ddply(testdata, ~dday, function(x) c(max_Occ = max(x$PredFCOcc_2hr, na.rm = TRUE)))
pred_obj <- prediction(predictions = preds[,"max_Occ"], labels = labs[, "Surge"])
perf <- performance(pred_obj, measure = "tpr", x.measure = "fpr")
plot(perf, colorize =  TRUE)
aucs[[18]] <- slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]
slot(performance(pred_obj, measure = "auc"), "y.values")[[1]]

```
I believe these results for 2016 confirm that projecting Forecasted Occupancy rate every 2 hours can bring value to the Surge planning effort. There are a number of ways we can drill down to the precise value of these forecasts in terms of precision, specificty, and timeliness: I have already developed visualization and summarization methods for describing forecast accuracy. Alternatively, Hook et al. used an Activity Monitoring ROC to visualize the tradeoff between accuracy and advance notice. In either case, we must first learn about how this policy could be alligned with the current ED huddle practices.

##

##Appendix: Prototypical Week in FC Occupancy Rate

```{r appendix1}
#fixing time zone attribute for visualization
attr(ptyp$Time, "tzone") <- "EST"

#show prototypical population shape
ggplot(ptyp , aes(Time, AvgFCOcc)) + ylab("FC Occupancy") + xlab("Weekday, Time") + geom_area(fill = "blue") + scale_x_datetime(date_labels = "%a, %R") + geom_vline(xintercept =  as.integer(as.POSIXct("2017-1-2 07:00"))) + geom_vline(xintercept = as.integer(as.POSIXct("2017-1-3 07:00"))) + geom_vline(xintercept = as.integer(as.POSIXct("2017-1-4 07:00"))) + geom_vline(xintercept = as.integer(as.POSIXct("2017-1-5 07:00"))) + geom_vline(xintercept = as.integer(as.POSIXct("2017-1-6 07:00"))) + geom_vline(xintercept = as.integer(as.POSIXct("2017-1-7 07:00")))

```

The graph above shows the average weekly progression of this metric, with the start of new days (7am) highlighted with a black vertical line. There is some truth to the inadequacy of this convention to capture to inverted U shape of the daily cycle. However, it may be inconclusive, as for only about half the days (Friday, Saturday, and Sunday) does the black demarcation not fall near the local minimum. 
