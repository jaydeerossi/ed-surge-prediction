---
title: "If and When Surges Occur in the Summer"
author: "Jack Rossi"
date: "May 31, 2017"
output: html_document
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Summary 

This script uses data from the Winter (December through February) and Summer (June through August) of 2015 and 2016. In order to better understand the surge phenomenon between seasons, we seek to count the number of surges during these periods, organized by month and weekday. 


```{r}

#preload functions

#install.packages("plyr")
library("knitr")
library("ggplot2")
library("grid") 
library("plyr")

get_rooms <- function(hour){
  
  if(hour%%24 >= 0){
    hour = hour%%24
    }
  
  if(hour %in% c(11,12,13,14,15,16,17,18,19,20,21,22,23,24,0)){
    Rooms = 42}
  else if (hour == 1){
    Rooms = 32}
  else if (hour %in% c(2, 3)){
    Rooms = 25}
  else if (hour %in% c(4, 5, 6, 7, 8)){
    Rooms = 22} 
  else if (hour == 9){
    Rooms = 26}
  else if (hour == 10){
    Rooms = 36}
  else {
    Rooms = NA}
  
  return(Rooms)
}

get_FC_rooms <- function(hrBlock, minBlock, FCHours = 2){
  #Sum up the number available rooms in the next FChours, weighted by the time spent with those rooms
  if (FCHours == 1){return(get_rooms(hrBlock))
  }
  FCRooms = 0
  
  for (g in 1:FCHours){
    FCRooms = FCRooms + get_rooms(hrBlock + g - 1)*(60-minBlock) + get_rooms(hrBlock + g)*minBlock  
  }
  FCRooms = FCRooms/(60*FCHours)
}
 
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

```{r}

#load and format data

ED <- read.csv("ED Data Summer 16.csv", header = TRUE)

colnames(ED)[1] = "Encounter.ID"
ED$Arrival <- as.POSIXct(ED$Arrival, format = "%m/%d/%Y %I:%M %p")
ED <- ED[!duplicated(ED$Encounter.ID),]

Summer16 <- ED[ED$Arrival >= as.POSIXct("2016-6-1") & ED$Arrival <= as.POSIXct("2016-8-31"),]
Summer16 <- Summer16[order(Summer16$Arrival),]
Summer16$ED.Room.Time <- as.POSIXct(Summer16$ED.Room.Time, format = "%m/%d/%Y %I:%M %p")
Summer16$Time.Left.ED <- as.POSIXct(Summer16$Time.Left.ED, format = "%m/%d/%Y %I:%M %p")

ED <- read.csv("ED2015DataFinal.csv", header = TRUE)

colnames(ED)[1] = "Encounter.ID"
ED$Arrival.Time <- as.POSIXct(ED$Arrival.Time, format = "%m/%d/%Y %H:%M")
ED <- ED[!duplicated(ED$Encounter.ID),]

Summer15 <-ED[ED$Arrival.Time >= as.POSIXct("2015-6-1") & ED$Arrival.Time <= as.POSIXct("2015-8-31"),]
Summer15 <- Summer15[order(Summer15$Arrival.Time),]
Summer15$ED.Room <- as.POSIXct(Summer15$ED.Room, format = "%m/%d/%Y %H:%M")
Summer15$Time.Left.ED <- as.POSIXct(Summer15$Time.Left.ED, format = "%m/%d/%Y %H:%M")


Winter15a <- ED[ED$Arrival.Time >= as.POSIXct("2015-12-1"),]
Winter15a$Time.Left.ED <- as.POSIXct(Winter15a$Time.Left.ED, format = "%m/%d/%Y %H:%M")

Winter15b <- read.csv("ED_Jan_Feb_2016.csv", header = TRUE)
Winter15b$Arrival.Time <- as.POSIXct(Winter15b$Arrival, format = "%m/%d/%Y %I:%M %p")
Winter15b$Time.Left.ED <- as.POSIXct(Winter15b$Time.Left.ED, format = "%m/%d/%Y %I:%M %p")
colnames(Winter15b)[1] = "Encounter.ID"
Winter15b <- Winter15b[!duplicated(Winter15b$Encounter.ID),]

Winter15 <- merge(Winter15a, Winter15b, all.y = TRUE, all.x = TRUE)

ED1 <- read.csv("QV December 2016.csv", header = TRUE)
ED2 <- read.csv("January 1-31 2017.csv", header = TRUE)
ED3 <- read.csv("February 1-26 2017.csv", header = TRUE)
EDa <- merge(ED1, ED2, all.x = TRUE, all.y = TRUE)
Winter16 <- merge(EDa, ED3, all.x = TRUE, all.y = TRUE)
colnames(Winter16)[1] = "Encounter.ID"
Winter16$Arrival <- as.POSIXct(Winter16$Arrival, format = "%m/%d/%Y %I:%M %p")
Winter16 <- Winter16[!duplicated(Winter16$Encounter.ID),]

Winter16$ED.Room.Time <- as.POSIXct(Winter16$ED.Room.Time, format = "%m/%d/%Y %I:%M %p")
Winter16$Time.Left.ED <- as.POSIXct(Winter16$Time.Left.ED, format = "%m/%d/%Y %I:%M %p")
```

### Calculate Occupancy Rate

We have the ED data partitioned by seasons and year. the code below shows calculations using the data from the Winter 2015-2016. We calculate the number in system and number of staffed rooms each time a patient arrives. The remaining data partitions are processed in this way as well. 

```{r echo = TRUE}

## Calculate Occupancy Rate and Adjust Day to delayed convention
for (m in 1:length(Winter15$Arrival.Time)){
  WholeED <- Winter15[!is.na(Winter15$Arrival.Time) & !is.na(Winter15$Time.Left.ED) &       !is.na(Winter15$ED.Room) & Winter15$Arrival.Time <= Winter15$Arrival.Time[m] & Winter15$Time.Left.ED >   Winter15$Arrival.Time[m],]
  Winter15$NIS[m] <- length(WholeED$Encounter.ID)
  Winter15$Rooms[m] <- get_rooms(as.POSIXlt(Winter15$Arrival.Time[m])$hour)
  Winter15$FCRooms[m] <- get_FC_rooms(as.POSIXlt(Winter15$Arrival.Time[m])$hour,   as.POSIXlt(Winter15$Arrival.Time[m])$min)
}

```

```{r}

Winter15$OccRate <- Winter15$NIS/Winter15$Rooms

for (m in 1:length(Summer15$Arrival.Time)){
  WholeED <- Summer15[!is.na(Summer15$Arrival.Time) & !is.na(Summer15$Time.Left.ED) &       !is.na(Summer15$ED.Room) & Summer15$Arrival.Time <= Summer15$Arrival.Time[m] & Summer15$Time.Left.ED >   Summer15$Arrival.Time[m],]
  Summer15$NIS[m] <- length(WholeED$Encounter.ID)
  Summer15$Rooms[m] <- get_rooms(as.POSIXlt(Summer15$Arrival.Time[m])$hour)
  Summer15$FCRooms[m] <- get_FC_rooms(as.POSIXlt(Summer15$Arrival.Time[m])$hour,   as.POSIXlt(Summer15$Arrival.Time[m])$min)
}

Summer15$OccRate <-  Summer15$NIS/Summer15$Rooms

for (m in 1:length(Summer16$Arrival)){
  WholeED <- Summer16[!is.na(Summer16$Arrival) & !is.na(Summer16$Time.Left.ED) &       !is.na(Summer16$ED.Room.Time) & Summer16$Arrival <= Summer16$Arrival[m] & Summer16$Time.Left.ED >   Summer16$Arrival[m],]
  Summer16$NIS[m] <- length(WholeED$Encounter.ID)
  Summer16$Rooms[m] <- get_rooms(as.POSIXlt(Summer16$Arrival[m])$hour)
  Summer16$FCRooms[m] <- get_FC_rooms(as.POSIXlt(Summer16$Arrival[m])$hour,   as.POSIXlt(Summer16$Arrival[m])$min)
}

Summer16$OccRate <- Summer16$NIS/Summer16$Rooms

for (m in 1:length(Winter16$Arrival)){
  WholeED <- Winter16[!is.na(Winter16$Arrival) & !is.na(Winter16$Time.Left.ED) &       !is.na(Winter16$ED.Room.Time) & Winter16$Arrival <= Winter16$Arrival[m] & Winter16$Time.Left.ED >   Winter16$Arrival[m],]
  Winter16$NIS[m] <- length(WholeED$Encounter.ID)
  Winter16$Rooms[m] <- get_rooms(as.POSIXlt(Winter16$Arrival[m])$hour)
  Winter16$FCRooms[m] <- get_FC_rooms(as.POSIXlt(Winter16$Arrival[m])$hour,   as.POSIXlt(Winter16$Arrival[m])$min)
  
}

Winter16$OccRate <- Winter16$NIS/Winter16$Rooms

#Adjust Arrival time stamps to reflect modified day convention

#extract time elements
Summer16$Month <-strftime(Summer16$Arrival, '%B') 
Summer16$Day <- as.POSIXlt(Summer16$Arrival)$yday
#cycle through each encounter 
for (g in 1:length(Summer16$Encounter.ID)){
  #adjust Day field to reflect modified day convention
  if (as.POSIXlt(Summer16$Arrival[g])$hour < 7){
    Summer16$Day[g] = Summer16$Day[g] - 1
  }
}
Summer16$WkDay <- strftime(Summer16$Arrival - 7*60*60, '%A')

#repeat protocol above for Summer 15 
Summer15$Month <- strftime(Summer15$Arrival.Time, '%B')
Summer15$Day <- as.POSIXlt(Summer15$Arrival.Time)$yday
for (g in 1:length(Summer15$Encounter.ID)){
  if (as.POSIXlt(Summer15$Arrival.Time[g])$hour < 7){
    Summer15$Day[g] = Summer15$Day[g] - 1
  }
}
Summer15$WkDay <- strftime(Summer15$Arrival.Time - 7*60*60, '%A')

#repeat protocol above for Winter 16
Winter16$Month <-strftime(Winter16$Arrival, '%B') 
Winter16$Day <- as.POSIXlt(Winter16$Arrival)$yday
for (g in 1:length(Winter16$Encounter.ID)){
  if (as.POSIXlt(Winter16$Arrival[g])$hour < 7 & Winter16$Day[g] != 0){
    Winter16$Day[g] = Winter16$Day[g] - 1
  }
}
Winter16$WkDay <- strftime(Winter16$Arrival - 7*60*60, '%A')

#repeat protocol above for Winter 15
Winter15$Month <- strftime(Winter15$Arrival.Time, '%B')
Winter15$Day <- as.POSIXlt(Winter15$Arrival.Time)$yday
for (g in 1:length(Winter15$Encounter.ID)){
  if (as.POSIXlt(Winter15$Arrival.Time[g])$hour < 7){
    Winter15$Day[g] = Winter15$Day[g] - 1
  }
}
Winter15$WkDay <- strftime(Winter15$Arrival.Time - 7*60*60, '%A')

```
```{r}

#Format factors for displaying results of SAC 
Summer15$WkDay <- factor(Summer15$WkDay, levels = c("Sunday", "Monday", 
   "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), ordered = TRUE)
Summer15$Month <- factor(Summer15$Month, levels = c("June", "July", "August"), ordered = TRUE)

Winter15$WkDay <- factor(Winter15$WkDay, levels = c("Sunday", "Monday", 
   "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), ordered = TRUE)
Winter15$Month <- factor(Winter15$Month, levels = c("December", "January", "February"), ordered = TRUE)

Summer16$WkDay <- factor(Summer16$WkDay, levels = c("Sunday", "Monday", 
   "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), ordered = TRUE)
Summer16$Month <- factor(Summer16$Month, levels = c("June", "July", "August"), ordered = TRUE)

Winter16$WkDay <- factor(Winter16$WkDay, levels = c("Sunday", "Monday", 
   "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), ordered = TRUE)
Winter16$Month <- factor(Winter16$Month, levels = c("December", "January", "February"), ordered = TRUE)

```

###Count Surges

Next we use the plyr package to process the data. For each of the seasonal partitions, we count the number of unique days (recall the modified 7am day convention) in which Occupancy Rate exceeds 1.60. In two separate commands, we sort these counts by month and weekday. 

```{r, echo = TRUE}
##Use ddply to count the number of Surges in Summer15, 16 

SurgesByMonth15 <- ddply(Summer15, ~Month, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.60]))))
SurgesByDOW15 <- ddply(Summer15, ~WkDay, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.60]))))


SurgesByMonth16 <- ddply(Summer16, ~Month, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.60]))))
SurgesByDOW16 <- ddply(Summer16, ~WkDay, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.60]))))

#Do same for winter 15, 16.

SurgesByMonthWint <- ddply(Winter16, ~Month, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.60]))))
SurgesByDOWWint <- ddply(Winter16, ~WkDay, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.60]))))

SurgesByMonthWint15 <- ddply(Winter15, ~Month, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.60]))))
SurgesByDOWWint15 <- ddply(Winter15, ~WkDay, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.60]))))

```

Let's take a close look at our calculations for the most recent data, Winter '16-'17.

```{r}
kable(SurgesByMonthWint, caption = "Instances of OccRate > 1.6, by Month, Winter '16-'17.")
kable(SurgesByDOWWint, caption =  "Instances of OccRate > 1.6, by Day of Week, Winter '16-'17.")
```

This winter was a busy one, with January and February sharing a total of 11 Surges. December saw an additional surge. Of these, most fell on either Monday, Tuesday, or Wednesday.

In order to claim that the OccRate > 1.6 criterion is representative of the ED's true decision making process, we should view the preceding results in relation to the actual number of Surge team call-ins in this same time period:


|# Surges |December[^1]|January|February|Total|
|---------|------------|-------|--------|:----|
|Sunday   |            |   1   |    2   |  3  |
|Monday   |    1       |   4   |    2   |  7  |
|Tuesday  |    1       |   3   |    2   |  6  |
|Wednesday|            |   2   |    3   |  5  |
|Thursday |            |   2   |    1   |  3  |
|Friday   |            |       |    1   |  1  |
|---------|------------|-------|--------|-----|
| Total   |    2       |   12  |   11   |  25 |


[^1]: note that the Surge Team records we used to create this table only go as far back as December 15th. December Surge figures are likely understated. 

The table above shows counts of surge activations from December '16 through February '17, as recorded by Sean Button. The counts are organized by weekday and Month. 

The ED does not explicitly use our Occupancy Rate (or any consistent) criterion when deciding to call in the Surge Team. Therefore we do not expect our numbers to line up exactly. However, we might be able to modify our criterion so as to better represent the set of actual Surge team activations. 

Let us reduce the definition of a Surge to an episode of Occupancy Rate exceeding 1.50, and repeat the plyr operation. 

```{r}
##Use ddply to count the number of Surges in Summer15, 16 

SurgesByMonth15 <- ddply(Summer15, ~Month, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.50]))))
SurgesByDOW15 <- ddply(Summer15, ~WkDay, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.50]))))


SurgesByMonth16 <- ddply(Summer16, ~Month, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.50]))))
SurgesByDOW16 <- ddply(Summer16, ~WkDay, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.50]))))

#Do same for winter 15, 16.

SurgesByMonthWint <- ddply(Winter16, ~Month, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.50]))))
SurgesByDOWWint <- ddply(Winter16, ~WkDay, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.50]))))

SurgesByMonthWint15 <- ddply(Winter15, ~Month, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.50]))))
SurgesByDOWWint15 <- ddply(Winter15, ~WkDay, function(x) c(no_surges = length(unique(x$Day[x$OccRate >= 1.50]))))

```

```{r}
kable(SurgesByMonthWint, caption = "Instances of OccRate > 1.50, by Month, Winter '16-'17.")
kable(SurgesByDOWWint, caption =  "Instances of OccRate > 1.50, by Day of Week, Winter '16-'17.")
```

As shown in the resulting dataframes, using the OccRate >= 1.5 criterion produces accurate results in comparison to the actual Surge records. Our calculations identify 25 surges over the Winter, whereas the records indicate that the surge team was called in 26 times. In addition, each calculation of number of surges for a month and weekday differs from the recorded value by no more than one (1 surge). I will use this new 1.50 criterion going forward.

The following graphs summarize the application of this new criterion. Blue bars show the number of surges on each weekday in the specified timeframe. Gold bars separate these counts by Month instead. 

##Number of Surges by Month and Weekday
```{r echo = TRUE}
#plotting data and outputting tables

Daily <- list(SurgesByDOW15, SurgesByDOW16, SurgesByDOWWint15, SurgesByDOWWint) 
Monthly <- list(SurgesByMonth15, SurgesByMonth16, SurgesByMonthWint15, SurgesByMonthWint)
title <- c("Summer 15", "Summer 16", "Winter 15-16", "Winter 16-17")

Dplots <- list()
Mplots <- list()
for (h in 1:length(Daily)){

  Dplots[[h]] <- ggplot(Daily[[h]], aes(WkDay, no_surges)) + geom_bar(stat = "identity", fill = "blue") +    ylim(0, 8) + ggtitle(title[h])
  Mplots[[h]] <- ggplot(Monthly[[h]], aes(Month, no_surges)) + geom_bar(stat = "identity", fill = "gold") +
    ylim(0, 15) + ggtitle(title[h])
  
}

print(Dplots)
print(Mplots)

```

From the weekday plots, it appears that there is a lagged relationship between ED census and Surge frequency - Surges appear to gradually peak toward midweek, whereas ED census is known to be maximal on Monday. One causal mechanism for this could be the the supposed prevalence of holds during midweek. The narrative goes that high census in the ED on Monday and Tuesday results in the filling of the floors with admits. Then, ED patients are more likely in midweek to be left without an admit bed (hold). It may be helpful to look into the correlation between surges and hold volumes. 

While there is considerable variation between years and seasons, there is some evidence that Surges are more common in late Summer (July and August) and mid-winter (January and February). While these facts are interesting, I don't believe them to be statistically significant. Moreover, I do not believe that there is currently enough operational flexibility to make these insights actionable in the near term. 

The last desired result is to predict a distribution of surge activations for Summer 17. In the following code, I will: 



1. Calculate a growth factor $alpha = \frac{W_{i+1}}{W_i}$, where $W_i$ is the patient volume in Winter two thousand $i$. This parameter will be estimated using the historical data for Winters 15 and 16. 

2. Adjust the occupancy rate data from Summer 2016 by multiplying each reading by the growth factor calculated above.

3. Based on this expected Occupancy progression, count the expected number of surges by month and weekday. 

```{r echo = TRUE}
#1.

alpha = length(Winter16$Encounter.ID)/length(Winter15$Encounter.ID)

#2.
Summer17 <- Summer16
Summer17$OccRate <- Summer17$OccRate*alpha

Summer17$WkDay <- factor(Summer17$WkDay, levels = c("Sunday", "Monday", 
   "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), ordered = TRUE)
Summer17$Month <- factor(Summer17$Month, levels = c("June", "July", "August"), ordered = TRUE)

#3.
SurgesByMonth17 <- ddply(Summer17, ~Month, function(x) c(predicted_surges = length(unique(x$Day[x$OccRate >= 1.50]))))
SurgesByDOW17 <- ddply(Summer17, ~WkDay, function(x) c(predicted_surges = length(unique(x$Day[x$OccRate >= 1.50]))))

```

Implementing this code, I can then visualize a forecast of the number of surges expected this Summer.

```{r}
ggplot(SurgesByDOW17, aes(WkDay, predicted_surges)) + geom_bar(stat = "identity", fill = "green") + ylim(0, 8) + ggtitle("Predicted Surge Activations, by Weekday, Summer 17.")
ggplot(SurgesByMonth17, aes(Month, predicted_surges)) + geom_bar(stat = "identity", fill = "green") + ylim(0, 15) + ggtitle("Predicted Surge Activations, by Month, Summer 17.")
```

In table form:

```{r}
kable(SurgesByDOW17, caption = "Predicted number of Surges, by Weekday, Summer 17.")
kable(SurgesByMonth17, caption = "Predicted number of Surges, by Month, Summer 17.")
```

The results of this analysis suggest that Surges in the coming Summer are an opportunity for improvement. On one hand, the incoming data will be relevant for progressing surge prediction analyses. On the other hand, about 20 instances of surge are plenty opportunity for improving response on an operational level. Though the summer months are perceived as less busy, we can still expect numerous cases of overcrowding; the level of effort dedicated to surge planning should continue to be reflective of this fact. 